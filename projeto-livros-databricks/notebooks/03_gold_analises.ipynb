{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===========================================\n",
        "# ðŸ“Š BOOKS_RATINGS_BY_SEQUENCE (Camada Gold)\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import col, avg, count, row_number, round\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# 1. Carregar livros e avaliaÃ§Ãµes jÃ¡ limpos (silver)\n",
        "df_books = spark.table(\"book_silver.books\")\n",
        "df_ratings = spark.table(\"book_silver.ratings\")\n",
        "\n",
        "# 2. Calcular nota mÃ©dia e contagem de avaliaÃ§Ãµes por livro\n",
        "ratings_agg = df_ratings.groupBy(\"isbn\").agg(\n",
        "    avg(\"rating\").alias(\"avg_rating\"),\n",
        "    count(\"rating\").alias(\"num_ratings\")\n",
        ")\n",
        "\n",
        "# 3. Juntar com livros para trazer tÃ­tulo, autor, ano\n",
        "books_with_ratings = df_books.join(ratings_agg, on=\"isbn\", how=\"inner\")\n",
        "\n",
        "# 4. Criar sequÃªncia de publicaÃ§Ã£o por autor (ordem crescente de ano)\n",
        "window_spec = Window.partitionBy(\"author\").orderBy(\"year\")\n",
        "\n",
        "books_with_sequence = books_with_ratings.withColumn(\n",
        "    \"book_order\", row_number().over(window_spec)\n",
        ")\n",
        "\n",
        "# 5. Selecionar e organizar as colunas finais\n",
        "df_gold = books_with_sequence.select(\n",
        "    \"author\", \"title\", \"year\", \"book_order\", \"avg_rating\", \"num_ratings\"\n",
        ")\n",
        "\n",
        "# 6. Salvar como tabela gold\n",
        "df_gold.write.mode(\"overwrite\").saveAsTable(\"book_gold.books_ratings_by_sequence\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# ðŸ“Š GOLD - TENDÃŠNCIA DE AVALIAÃ‡ÃƒO POR SEQUÃŠNCIA (1Âº ao 20Âº livro)\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import avg, count, round, col\n",
        "\n",
        "# Carregar a tabela de sequÃªncia de livros por autor\n",
        "df_sequence = spark.table(\"book_gold.books_ratings_by_sequence\")\n",
        "\n",
        "# Filtrar livros atÃ© a 20Âª posiÃ§Ã£o\n",
        "df_limit_20 = df_sequence.filter(col(\"book_order\") <= 20)\n",
        "\n",
        "# Calcular a mÃ©dia das notas por posiÃ§Ã£o de lanÃ§amento\n",
        "df_trend = df_limit_20.groupBy(\"book_order\").agg(\n",
        "    round(avg(\"avg_rating\"), 3).alias(\"avg_rating_por_posicao\"),\n",
        "    count(\"avg_rating\").alias(\"total_livros\")\n",
        ").orderBy(\"book_order\")\n",
        "\n",
        "# Exibir resultado em tabela\n",
        "display(df_trend)\n",
        "\n",
        "# Salvar como tabela gold auxiliar\n",
        "df_trend.write.mode(\"overwrite\").saveAsTable(\"book_gold.rating_trend_by_sequence\")\n",
        "\n",
        "# ===========================================\n",
        "# ðŸ“ˆ VISUALIZAÃ‡ÃƒO\n",
        "# ===========================================\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Converter para pandas para plotar\n",
        "df_pd = df_trend.toPandas()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_pd[\"book_order\"], df_pd[\"avg_rating_por_posicao\"], marker='o')\n",
        "plt.title(\"TendÃªncia da AvaliaÃ§Ã£o MÃ©dia por Ordem de LanÃ§amento\")\n",
        "plt.xlabel(\"PosiÃ§Ã£o do Livro na Carreira do Autor\")\n",
        "plt.ylabel(\"Nota MÃ©dia\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#1. TendÃªncia de nota por ordem de lanÃ§amento\n",
        "\n",
        "#A anÃ¡lise indica que os primeiros livros publicados por um autor tendem a receber avaliaÃ§Ãµes mais #altas, especialmente os dois primeiros. A partir do terceiro ou quarto lanÃ§amento, a mÃ©dia de notas #tende a se estabilizar. Isso pode estar relacionado Ã  expectativa inicial dos leitores ou Ã  #dificuldade de manter um alto nÃ­vel de inovaÃ§Ã£o ao longo da carreira. Ã‰ importante destacar que #esta anÃ¡lise nÃ£o considera o tempo entre lanÃ§amentos e pode ter viÃ©s para autores com poucos livros #publicados.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# ðŸ“Š GOLD - INTERVALO ENTRE LIVROS VS NOTA\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import col, avg, round, lag\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# 1. Carregar tabela gold com sequÃªncias\n",
        "books_seq = spark.table(\"book_gold.books_ratings_by_sequence\")\n",
        "\n",
        "# 2. Criar coluna com o ano do livro anterior\n",
        "window = Window.partitionBy(\"author\").orderBy(\"book_order\")\n",
        "books_with_lag = books_seq.withColumn(\"prev_year\", lag(\"year\").over(window))\n",
        "\n",
        "# 3. Calcular intervalo entre lanÃ§amentos (em anos)\n",
        "books_with_diff = books_with_lag.withColumn(\n",
        "    \"years_since_last\", col(\"year\") - col(\"prev_year\")\n",
        ").filter(col(\"book_order\") > 1)\n",
        "\n",
        "# 4. Salvar tabela com gaps e notas\n",
        "books_with_diff.write.mode(\"overwrite\").saveAsTable(\"book_gold.rating_by_release_gap\")\n",
        "\n",
        "# ===========================================\n",
        "# ðŸ“ˆ VISUALIZAÃ‡ÃƒO DA MÃ‰DIA POR INTERVALO\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import count\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Agrupar por intervalo e calcular mÃ©dia das notas\n",
        "df_gap_trend = books_with_diff.groupBy(\"years_since_last\").agg(\n",
        "    round(avg(\"avg_rating\"), 2).alias(\"avg_rating\"),\n",
        "    count(\"avg_rating\").alias(\"num_livros\")\n",
        ").orderBy(\"years_since_last\")\n",
        "\n",
        "# Mostrar dados em tabela\n",
        "display(df_gap_trend)\n",
        "\n",
        "# Converter para pandas para plotar\n",
        "df_pd = df_gap_trend.toPandas()\n",
        "\n",
        "# ===========================================\n",
        "# ðŸ“ˆ VISUALIZAÃ‡ÃƒO\n",
        "# ===========================================\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_pd[\"years_since_last\"], df_pd[\"avg_rating\"], marker='o')\n",
        "plt.title(\"Nota MÃ©dia por Intervalo de LanÃ§amento entre Livros\")\n",
        "plt.xlabel(\"Anos desde o Ãºltimo livro\")\n",
        "plt.ylabel(\"Nota mÃ©dia\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#2. Intervalo entre lanÃ§amentos e nota mÃ©dia\n",
        "\n",
        "#NÃ£o foi observada uma relaÃ§Ã£o linear entre o intervalo de tempo entre lanÃ§amentos e a nota mÃ©dia #dos livros. Autores que publicam com intervalos curtos (entre um e trÃªs anos) apresentam desempenho #semelhante Ã queles com intervalos mais longos. Isso sugere que o tempo entre publicaÃ§Ãµes, por si #sÃ³, nÃ£o Ã© um fator determinante para avaliaÃ§Ãµes melhores. A consistÃªncia na produÃ§Ã£o pode ter papel #mais relevante que pausas prolongadas.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# ðŸ“Š GOLD - QTD DE LIVROS VS NOTA MÃ‰DIA POR AUTOR (COM OUTLIERS E TENDÃŠNCIA)\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import count, avg, round, col\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1. Carregar tabela de livros por sequÃªncia\n",
        "df_sequence = spark.table(\"book_gold.books_ratings_by_sequence\")\n",
        "\n",
        "# 2. Agrupar por autor para obter total de livros e mÃ©dia de nota\n",
        "df_author_summary = df_sequence.groupBy(\"author\").agg(\n",
        "    count(\"title\").alias(\"qtd_livros\"),\n",
        "    round(avg(\"avg_rating\"), 2).alias(\"media_avaliacao\")\n",
        ").filter((col(\"qtd_livros\") >= 2) & (col(\"qtd_livros\") <= 100))\n",
        "\n",
        "# 3. Salvar como tabela auxiliar\n",
        "df_author_summary.write.mode(\"overwrite\").saveAsTable(\"book_gold.books_volume_vs_avg\")\n",
        "\n",
        "# 4. VisualizaÃ§Ã£o: grÃ¡fico de dispersÃ£o com linha de tendÃªncia e destaque de outliers\n",
        "# Converter para pandas\n",
        "df_pd = df_author_summary.toPandas()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# DispersÃ£o\n",
        "plt.scatter(df_pd[\"qtd_livros\"], df_pd[\"media_avaliacao\"], alpha=0.6, label=\"Autores\")\n",
        "\n",
        "# Linha de tendÃªncia (regressÃ£o linear)\n",
        "z = np.polyfit(df_pd[\"qtd_livros\"], df_pd[\"media_avaliacao\"], 1)\n",
        "p = np.poly1d(z)\n",
        "plt.plot(df_pd[\"qtd_livros\"], p(df_pd[\"qtd_livros\"]), \"r--\", label=\"TendÃªncia\")\n",
        "\n",
        "# Outliers: autores com 80+ livros e mÃ©dia > 4.5\n",
        "outliers = df_pd[(df_pd[\"qtd_livros\"] >= 80) & (df_pd[\"media_avaliacao\"] > 4.5)]\n",
        "plt.scatter(outliers[\"qtd_livros\"], outliers[\"media_avaliacao\"], color='orange', edgecolors='black', label=\"Outliers\")\n",
        "\n",
        "# ===========================================\n",
        "# ðŸ“ˆ VISUALIZAÃ‡ÃƒO\n",
        "# ===========================================\n",
        "plt.title(\"Quantidade de Livros vs MÃ©dia de AvaliaÃ§Ã£o por Autor (atÃ© 100 livros)\")\n",
        "plt.xlabel(\"Quantidade de Livros\")\n",
        "plt.ylabel(\"MÃ©dia das Notas\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#3. Quantidade de livros publicados e nota mÃ©dia\n",
        "\n",
        "#HÃ¡ uma leve tendÃªncia de que autores com maior nÃºmero de livros publicados apresentem uma mÃ©dia de #avaliaÃ§Ã£o um pouco inferior. Ainda assim, alguns autores com alta produtividade conseguem manter #notas elevadas, aparecendo como exceÃ§Ãµes. Isso pode indicar que, embora a manutenÃ§Ã£o da qualidade #com volume alto seja desafiadora, ela Ã© possÃ­vel para certos perfis de autores.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# ðŸ“Š GOLD - IDADE DO LEITOR VS ANO DO LIVRO LIDO\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import col, floor, avg, count, when\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Carregar tabelas silver\n",
        "books = spark.table(\"book_silver.books\")\n",
        "ratings = spark.table(\"book_silver.ratings\")\n",
        "users = spark.table(\"book_silver.users\")\n",
        "\n",
        "# 2. Join completo\n",
        "ratings_books = ratings.join(books, on=\"isbn\", how=\"inner\")\n",
        "rating_data = ratings_books.join(users, on=\"user_id\", how=\"inner\")\n",
        "\n",
        "# 3. Filtrar dados consistentes\n",
        "rating_clean = rating_data.filter(\n",
        "    (col(\"age\").isNotNull()) & (col(\"age\") >= 10) & (col(\"age\") <= 100) &\n",
        "    (col(\"year\").isNotNull()) & (col(\"year\") >= 1450) & (col(\"year\") <= 2025)\n",
        ")\n",
        "\n",
        "# 4. Criar faixa etÃ¡ria\n",
        "rating_with_faixa = rating_clean.withColumn(\n",
        "    \"faixa_etaria\", (floor(col(\"age\") / 10) * 10).cast(\"int\")\n",
        ")\n",
        "\n",
        "# 5. Agrupar por faixa etÃ¡ria e calcular mÃ©dia do ano do livro\n",
        "df_idade_vs_ano = rating_with_faixa.groupBy(\"faixa_etaria\").agg(\n",
        "    round(avg(\"year\"), 1).alias(\"media_ano_lido\"),\n",
        "    count(\"isbn\").alias(\"total_livros_lidos\")\n",
        ").orderBy(\"faixa_etaria\")\n",
        "\n",
        "# 6. Salvar como tabela auxiliar\n",
        "df_idade_vs_ano.write.mode(\"overwrite\").saveAsTable(\"book_gold.reader_age_vs_book_year\")\n",
        "\n",
        "# ===========================================\n",
        "# ðŸ“ˆ VISUALIZAÃ‡ÃƒO\n",
        "# ===========================================\n",
        "# Converter para pandas\n",
        "df_pd = df_idade_vs_ano.toPandas()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_pd[\"faixa_etaria\"], df_pd[\"media_ano_lido\"], marker='o')\n",
        "plt.title(\"MÃ©dia do Ano dos Livros Lidos por Faixa EtÃ¡ria do Leitor\")\n",
        "plt.xlabel(\"Faixa EtÃ¡ria\")\n",
        "plt.ylabel(\"Ano MÃ©dio dos Livros Lidos\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#4. Faixa etÃ¡ria do leitor e ano do livro lido\n",
        "\n",
        "#Os dados mostram que leitores mais jovens tendem a ler livros mais recentes, enquanto leitores com #mais idade consomem obras publicadas hÃ¡ mais tempo. Essa relaÃ§Ã£o entre faixa etÃ¡ria e Ã©poca da obra #lida pode refletir preferÃªncias geracionais ou maior familiaridade com obras de diferentes perÃ­odos.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# ðŸ“Š GOLD - AVALIAÃ‡ÃƒO POR IDADE DO LEITOR E ANO DO LIVRO (SUAVIZAÃ‡ÃƒO + ANOTAÃ‡Ã•ES)\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import col, floor, avg, count, round, expr\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from scipy.ndimage import uniform_filter\n",
        "\n",
        "# 1. Carregar tabelas base\n",
        "books = spark.table(\"book_silver.books\")\n",
        "ratings = spark.table(\"book_silver.ratings\")\n",
        "users = spark.table(\"book_silver.users\")\n",
        "\n",
        "# 2. Join completo\n",
        "ratings_books = ratings.join(books, on=\"isbn\", how=\"inner\")\n",
        "rating_data = ratings_books.join(users, on=\"user_id\", how=\"inner\")\n",
        "\n",
        "# 3. Filtrar dados vÃ¡lidos\n",
        "rating_clean = rating_data.filter(\n",
        "    (col(\"age\").isNotNull()) & (col(\"age\") >= 10) & (col(\"age\") <= 100) &\n",
        "    (col(\"year\").isNotNull()) & (col(\"year\") >= 1450) & (col(\"year\") <= 2025)\n",
        ")\n",
        "\n",
        "# 4. Criar faixas\n",
        "rating_with_bins = rating_clean.withColumn(\"faixa_etaria\", (floor(col(\"age\") / 10) * 10).cast(\"int\")) \\\n",
        "    .withColumn(\"ano_livro\", (floor(col(\"year\") / 10) * 10).cast(\"int\"))\n",
        "\n",
        "# 5. Agrupar e calcular mÃ©dias\n",
        "df_avaliacoes = rating_with_bins.groupBy(\"faixa_etaria\", \"ano_livro\").agg(\n",
        "    round(avg(\"rating\"), 2).alias(\"avg_rating\"),\n",
        "    count(\"rating\").alias(\"total_avaliacoes\")\n",
        ").orderBy(\"faixa_etaria\", \"ano_livro\")\n",
        "\n",
        "# 6. Salvar tabela gold auxiliar\n",
        "df_avaliacoes.write.mode(\"overwrite\").saveAsTable(\"book_gold.age_book_year_rating\")\n",
        "\n",
        "# 7. VisualizaÃ§Ã£o: mapa de calor com suavizaÃ§Ã£o e anotaÃ§Ãµes\n",
        "# Converter para pandas\n",
        "pdf = df_avaliacoes.toPandas()\n",
        "\n",
        "# Pivot para heatmap\n",
        "pivot = pdf.pivot(index=\"faixa_etaria\", columns=\"ano_livro\", values=\"avg_rating\")\n",
        "\n",
        "# Aplicar suavizaÃ§Ã£o com filtro de mÃ©dia (janela 3x3)\n",
        "smoothed = uniform_filter(pivot.fillna(0), size=3)\n",
        "\n",
        "# Criar DataFrame suavizado com mesmos Ã­ndices para anotaÃ§Ã£o\n",
        "smoothed_df = pd.DataFrame(smoothed, index=pivot.index, columns=pivot.columns)\n",
        "\n",
        "# ===========================================\n",
        "# ðŸ“ˆ VISUALIZAÃ‡ÃƒO\n",
        "# ===========================================\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.heatmap(smoothed_df, annot=smoothed_df.round(2), fmt=\".2f\", cmap=\"YlGnBu\", linewidths=0.5)\n",
        "plt.title(\"MÃ©dia de AvaliaÃ§Ã£o por Faixa EtÃ¡ria do Leitor e Ano do Livro (Suavizado)\")\n",
        "plt.xlabel(\"Ano do Livro (dÃ©cadas)\")\n",
        "plt.ylabel(\"Faixa EtÃ¡ria do Leitor\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#6. Diversidade de autores por faixa etÃ¡ria\n",
        "\n",
        "#Leitores com idade entre 30 e 45 anos tendem a ter contato com uma maior variedade de autores, #especialmente nas faixas entre 12 e 24 autores distintos. Por outro lado, leitores mais jovens (atÃ© #20 anos) e mais velhos (acima de 65) demonstram menor diversidade. Isso sugere que, na fase adulta, #hÃ¡ maior disposiÃ§Ã£o para explorar diferentes estilos e autores.\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# ðŸ“Š GOLD - DISTRIBUIÃ‡ÃƒO DE DIVERSIDADE DE AUTORES POR FAIXA ETÃRIA DO LEITOR\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import col, floor, countDistinct\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Carregar tabelas silver\n",
        "books = spark.table(\"book_silver.books\")\n",
        "ratings = spark.table(\"book_silver.ratings\")\n",
        "users = spark.table(\"book_silver.users\")\n",
        "\n",
        "# 2. Join completo\n",
        "ratings_books = ratings.join(books, on=\"isbn\", how=\"inner\")\n",
        "rating_data = ratings_books.join(users, on=\"user_id\", how=\"inner\")\n",
        "\n",
        "# 3. Filtrar dados vÃ¡lidos\n",
        "rating_clean = rating_data.filter(\n",
        "    (col(\"age\").isNotNull()) & (col(\"age\") >= 10) & (col(\"age\") <= 100) &\n",
        "    (col(\"author\").isNotNull()) & (col(\"author\") != \"\")\n",
        ")\n",
        "\n",
        "# 4. Criar faixa etÃ¡ria de 5 em 5 anos\n",
        "rating_with_bins = rating_clean.withColumn(\"faixa_etaria\", (floor(col(\"age\") / 5) * 5).cast(\"int\"))\n",
        "\n",
        "# 5. Calcular autores distintos por leitor\n",
        "user_author_counts = rating_with_bins.groupBy(\"user_id\", \"faixa_etaria\").agg(\n",
        "    countDistinct(\"author\").alias(\"autores_distintos\")\n",
        ")\n",
        "\n",
        "# 6. Aplicar limite e criar faixas de diversidade de autores (3 em 3)\n",
        "auth_bin_df = user_author_counts.filter(col(\"autores_distintos\") <= 30) \\\n",
        "    .withColumn(\"faixa_autores\", (floor(col(\"autores_distintos\") / 3) * 3).cast(\"int\"))\n",
        "\n",
        "# 7. Contar usuÃ¡rios por faixa de idade e faixa de diversidade\n",
        "distribuicao_df = auth_bin_df.groupBy(\"faixa_etaria\", \"faixa_autores\").count().orderBy(\"faixa_etaria\", \"faixa_autores\")\n",
        "\n",
        "# 8. Converter para pandas e pivotar\n",
        "pdf = distribuicao_df.toPandas()\n",
        "pivot = pdf.pivot(index=\"faixa_autores\", columns=\"faixa_etaria\", values=\"count\").fillna(0)\n",
        "\n",
        "# ===========================================\n",
        "# ðŸ“ˆ VISUALIZAÃ‡ÃƒO\n",
        "# ===========================================\n",
        "# 9. Visualizar como heatmap\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.heatmap(pivot, annot=True, fmt=\".0f\", cmap=\"YlOrBr\", linewidths=0.5)\n",
        "plt.title(\"DistribuiÃ§Ã£o de Diversidade de Autores por Faixa EtÃ¡ria do Leitor (atÃ© 30 autores, agrupado de 3 em 3)\")\n",
        "plt.xlabel(\"Faixa EtÃ¡ria (anos)\")\n",
        "plt.ylabel(\"NÃºmero de Autores Distintos (agrupado de 3 em 3)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#6. Diversidade de autores por faixa etÃ¡ria\n",
        "\n",
        "#Leitores com idade entre 30 e 45 anos tendem a ter contato com uma maior variedade de autores, #especialmente nas faixas entre 12 e 24 autores distintos. Por outro lado, leitores mais jovens (atÃ© #20 anos) e mais velhos (acima de 65) demonstram menor diversidade. Isso sugere que, na fase adulta, #hÃ¡ maior disposiÃ§Ã£o para explorar diferentes estilos e autores.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# ðŸ“Š GOLD - CLUSTERIZAÃ‡ÃƒO DE AUTORES\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import col, avg, stddev, count, round\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Carregar tabela de sequÃªncia com notas por livro\n",
        "df = spark.table(\"book_gold.books_ratings_by_sequence\")\n",
        "\n",
        "# 2. Agregar por autor para gerar mÃ©tricas\n",
        "autores_df = df.groupBy(\"author\").agg(\n",
        "    count(\"title\").alias(\"qtd_livros\"),\n",
        "    round(avg(\"avg_rating\"), 2).alias(\"media_nota\"),\n",
        "    round(stddev(\"avg_rating\"), 2).alias(\"desvio_nota\"),\n",
        "    round(avg(\"year\"), 0).alias(\"ano_medio\")\n",
        ").filter(col(\"qtd_livros\") >= 3)\n",
        "\n",
        "# 3. Vetorizar para ML\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"qtd_livros\", \"media_nota\", \"desvio_nota\", \"ano_medio\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "vectorized_df = assembler.transform(autores_df)\n",
        "\n",
        "# 4. Padronizar os dados\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled\", withMean=True, withStd=True)\n",
        "scaler_model = scaler.fit(vectorized_df)\n",
        "scaled_df = scaler_model.transform(vectorized_df)\n",
        "\n",
        "# 5. Aplicar KMeans (definindo 4 clusters)\n",
        "kmeans = KMeans(featuresCol=\"scaled\", predictionCol=\"cluster\", k=4, seed=42)\n",
        "model = kmeans.fit(scaled_df)\n",
        "clustered = model.transform(scaled_df)\n",
        "\n",
        "# 6. Converter para pandas para visualizaÃ§Ã£o\n",
        "pdf = clustered.select(\"author\", \"qtd_livros\", \"media_nota\", \"desvio_nota\", \"ano_medio\", \"cluster\").toPandas()\n",
        "\n",
        "# ===========================================\n",
        "# ðŸ“ˆ VISUALIZAÃ‡ÃƒO\n",
        "# ===========================================\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=pdf, x=\"qtd_livros\", y=\"media_nota\", hue=\"cluster\", palette=\"Set2\")\n",
        "plt.title(\"ClusterizaÃ§Ã£o de Autores por Volume e Nota MÃ©dia\")\n",
        "plt.xlabel(\"Quantidade de Livros\")\n",
        "plt.ylabel(\"MÃ©dia das Notas\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 8. Salvar tabela com clusters\n",
        "spark.createDataFrame(pdf).write.mode(\"overwrite\").saveAsTable(\"book_gold.authors_clustered\")\n",
        "\n",
        "#7. ClusterizaÃ§Ã£o de autores\n",
        "\n",
        "#A segmentaÃ§Ã£o dos autores com base em volume de livros publicados, nota mÃ©dia, desvio das #avaliaÃ§Ãµes e ano mÃ©dio das obras permitiu identificar perfis distintos. Foram encontrados #agrupamentos com autores prolÃ­ficos e bem avaliados, autores com alta variabilidade nas avaliaÃ§Ãµes #e autores mais recentes com desempenho positivo. Esta anÃ¡lise permite mapear padrÃµes de atuaÃ§Ã£o no #cenÃ¡rio literÃ¡rio.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# ðŸŒ GOLD - CLUSTERIZAÃ‡ÃƒO DE PAÃSES POR FAIXAS ETÃRIAS (PROPORÃ‡ÃƒO POR FAIXA ORDENADO POR TOTAL)\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import col, lower, split, trim, regexp_replace, count, floor, sum as sum_\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Carregar tabela de usuÃ¡rios\n",
        "users = spark.table(\"book_silver.users\")\n",
        "\n",
        "# 2. Extrair paÃ­s apÃ³s a segunda vÃ­rgula\n",
        "users_country = users.withColumn(\"country_raw\", split(col(\"location\"), \",\").getItem(2)) \\\n",
        "    .withColumn(\"country\", regexp_replace(trim(lower(col(\"country_raw\"))), \"[^a-z ]\", \"\")) \\\n",
        "    .filter(col(\"country\").isNotNull() & (col(\"country\") != \"\"))\n",
        "\n",
        "# 3. Filtrar idades vÃ¡lidas\n",
        "users_valid_age = users_country.filter((col(\"age\") >= 10) & (col(\"age\") <= 100))\n",
        "\n",
        "# 4. Criar faixa etÃ¡ria de 5 em 5 anos\n",
        "users_with_bins = users_valid_age.withColumn(\"faixa_etaria\", (floor(col(\"age\") / 5) * 5).cast(\"int\"))\n",
        "\n",
        "# 5. Contar nÃºmero de leitores por paÃ­s e faixa etÃ¡ria\n",
        "df_country_faixa = users_with_bins.groupBy(\"country\", \"faixa_etaria\").agg(count(\"user_id\").alias(\"total\"))\n",
        "\n",
        "# 6. Selecionar os 30 paÃ­ses com mais leitores no total\n",
        "total_by_country = df_country_faixa.groupBy(\"country\").agg(sum_(\"total\").alias(\"total_pais\"))\n",
        "top30_countries = total_by_country.orderBy(col(\"total_pais\").desc()).limit(30)\n",
        "df_top30 = df_country_faixa.join(top30_countries.select(\"country\"), on=\"country\", how=\"inner\")\n",
        "\n",
        "# 7. Calcular proporÃ§Ã£o por faixa etÃ¡ria em cada paÃ­s\n",
        "df_top30_total = df_top30.join(total_by_country.withColumnRenamed(\"total_pais\", \"total_pais_all\"), on=\"country\")\n",
        "df_top30_prop = df_top30_total.withColumn(\"proporcao\", (col(\"total\") / col(\"total_pais_all\")).cast(\"double\"))\n",
        "\n",
        "# 8. Pivotar proporÃ§Ãµes por faixa etÃ¡ria\n",
        "df_pivot = df_top30_prop.groupBy(\"country\").pivot(\"faixa_etaria\").agg({\"proporcao\": \"avg\"}).na.fill(0)\n",
        "\n",
        "# 9. ClusterizaÃ§Ã£o com KMeans por distribuiÃ§Ã£o etÃ¡ria proporcional\n",
        "features = [col for col in df_pivot.columns if col != \"country\"]\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "data_vector = assembler.transform(df_pivot)\n",
        "\n",
        "kmeans = KMeans(k=4, seed=42, featuresCol=\"features\", predictionCol=\"cluster\")\n",
        "model = kmeans.fit(data_vector)\n",
        "clustered = model.transform(data_vector)\n",
        "\n",
        "# ===========================================\n",
        "# ðŸ“ˆ VISUALIZAÃ‡ÃƒO\n",
        "# ===========================================\n",
        "# 10. Expandir para grÃ¡fico de bolhas com proporÃ§Ã£o e ordenaÃ§Ã£o por total\n",
        "df_expanded = df_top30_prop.join(clustered.select(\"country\", \"cluster\"), on=\"country\", how=\"inner\")\n",
        "df_expanded = df_expanded.join(top30_countries, on=\"country\")\n",
        "pdf_bubbles = df_expanded.select(\"country\", \"faixa_etaria\", \"proporcao\", \"cluster\", \"total_pais\").toPandas()\n",
        "pdf_bubbles[\"country\"] = pd.Categorical(pdf_bubbles[\"country\"], \n",
        "    categories=pdf_bubbles.groupby(\"country\")[\"total_pais\"].max().sort_values(ascending=False).index,\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "# 11. VisualizaÃ§Ã£o com grÃ¡fico de bolhas\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.scatterplot(\n",
        "    data=pdf_bubbles,\n",
        "    x=\"faixa_etaria\",\n",
        "    y=\"country\",\n",
        "    size=\"proporcao\",\n",
        "    hue=\"cluster\",\n",
        "    sizes=(40, 800),\n",
        "    alpha=0.7,\n",
        "    palette=\"Set2\"\n",
        ")\n",
        "plt.title(\"DistribuiÃ§Ã£o Proporcional de Leitores por Faixa EtÃ¡ria e PaÃ­s (Ordenado por Volume)\")\n",
        "plt.xlabel(\"Faixa EtÃ¡ria\")\n",
        "plt.ylabel(\"PaÃ­s (ordenado por total de leitores)\")\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#8. ClusterizaÃ§Ã£o de paÃ­ses por faixa etÃ¡ria\n",
        "\n",
        "#A anÃ¡lise por paÃ­s, considerando a proporÃ§Ã£o de leitores por faixa etÃ¡ria, mostrou perfis distintos #entre as naÃ§Ãµes. PaÃ­ses como Estados Unidos, Ãndia e Alemanha apresentaram maior equilÃ­brio etÃ¡rio, #enquanto outros se destacaram por concentraÃ§Ãµes em faixas mais jovens. Essa informaÃ§Ã£o pode indicar #variaÃ§Ãµes no hÃ¡bito de leitura e ajudar a identificar oportunidades de atuaÃ§Ã£o segmentada por #regiÃ£o.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
