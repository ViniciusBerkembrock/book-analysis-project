{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===========================================\n",
        "# 📊 BOOKS_RATINGS_BY_SEQUENCE (Camada Gold)\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import col, avg, count, row_number, round\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# 1. Carregar livros e avaliações já limpos (silver)\n",
        "df_books = spark.table(\"book_silver.books\")\n",
        "df_ratings = spark.table(\"book_silver.ratings\")\n",
        "\n",
        "# 2. Calcular nota média e contagem de avaliações por livro\n",
        "ratings_agg = df_ratings.groupBy(\"isbn\").agg(\n",
        "    avg(\"rating\").alias(\"avg_rating\"),\n",
        "    count(\"rating\").alias(\"num_ratings\")\n",
        ")\n",
        "\n",
        "# 3. Juntar com livros para trazer título, autor, ano\n",
        "books_with_ratings = df_books.join(ratings_agg, on=\"isbn\", how=\"inner\")\n",
        "\n",
        "# 4. Criar sequência de publicação por autor (ordem crescente de ano)\n",
        "window_spec = Window.partitionBy(\"author\").orderBy(\"year\")\n",
        "\n",
        "books_with_sequence = books_with_ratings.withColumn(\n",
        "    \"book_order\", row_number().over(window_spec)\n",
        ")\n",
        "\n",
        "# 5. Selecionar e organizar as colunas finais\n",
        "df_gold = books_with_sequence.select(\n",
        "    \"author\", \"title\", \"year\", \"book_order\", \"avg_rating\", \"num_ratings\"\n",
        ")\n",
        "\n",
        "# 6. Salvar como tabela gold\n",
        "df_gold.write.mode(\"overwrite\").saveAsTable(\"book_gold.books_ratings_by_sequence\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# 📊 GOLD - TENDÊNCIA DE AVALIAÇÃO POR SEQUÊNCIA (1º ao 20º livro)\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import avg, count, round, col\n",
        "\n",
        "# Carregar a tabela de sequência de livros por autor\n",
        "df_sequence = spark.table(\"book_gold.books_ratings_by_sequence\")\n",
        "\n",
        "# Filtrar livros até a 20ª posição\n",
        "df_limit_20 = df_sequence.filter(col(\"book_order\") <= 20)\n",
        "\n",
        "# Calcular a média das notas por posição de lançamento\n",
        "df_trend = df_limit_20.groupBy(\"book_order\").agg(\n",
        "    round(avg(\"avg_rating\"), 3).alias(\"avg_rating_por_posicao\"),\n",
        "    count(\"avg_rating\").alias(\"total_livros\")\n",
        ").orderBy(\"book_order\")\n",
        "\n",
        "# Exibir resultado em tabela\n",
        "display(df_trend)\n",
        "\n",
        "# Salvar como tabela gold auxiliar\n",
        "df_trend.write.mode(\"overwrite\").saveAsTable(\"book_gold.rating_trend_by_sequence\")\n",
        "\n",
        "# ===========================================\n",
        "# 📈 VISUALIZAÇÃO\n",
        "# ===========================================\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Converter para pandas para plotar\n",
        "df_pd = df_trend.toPandas()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_pd[\"book_order\"], df_pd[\"avg_rating_por_posicao\"], marker='o')\n",
        "plt.title(\"Tendência da Avaliação Média por Ordem de Lançamento\")\n",
        "plt.xlabel(\"Posição do Livro na Carreira do Autor\")\n",
        "plt.ylabel(\"Nota Média\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#1. Tendência de nota por ordem de lançamento\n",
        "\n",
        "#A análise indica que os primeiros livros publicados por um autor tendem a receber avaliações mais #altas, especialmente os dois primeiros. A partir do terceiro ou quarto lançamento, a média de notas #tende a se estabilizar. Isso pode estar relacionado à expectativa inicial dos leitores ou à #dificuldade de manter um alto nível de inovação ao longo da carreira. É importante destacar que #esta análise não considera o tempo entre lançamentos e pode ter viés para autores com poucos livros #publicados.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# 📊 GOLD - INTERVALO ENTRE LIVROS VS NOTA\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import col, avg, round, lag\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# 1. Carregar tabela gold com sequências\n",
        "books_seq = spark.table(\"book_gold.books_ratings_by_sequence\")\n",
        "\n",
        "# 2. Criar coluna com o ano do livro anterior\n",
        "window = Window.partitionBy(\"author\").orderBy(\"book_order\")\n",
        "books_with_lag = books_seq.withColumn(\"prev_year\", lag(\"year\").over(window))\n",
        "\n",
        "# 3. Calcular intervalo entre lançamentos (em anos)\n",
        "books_with_diff = books_with_lag.withColumn(\n",
        "    \"years_since_last\", col(\"year\") - col(\"prev_year\")\n",
        ").filter(col(\"book_order\") > 1)\n",
        "\n",
        "# 4. Salvar tabela com gaps e notas\n",
        "books_with_diff.write.mode(\"overwrite\").saveAsTable(\"book_gold.rating_by_release_gap\")\n",
        "\n",
        "# ===========================================\n",
        "# 📈 VISUALIZAÇÃO DA MÉDIA POR INTERVALO\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import count\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Agrupar por intervalo e calcular média das notas\n",
        "df_gap_trend = books_with_diff.groupBy(\"years_since_last\").agg(\n",
        "    round(avg(\"avg_rating\"), 2).alias(\"avg_rating\"),\n",
        "    count(\"avg_rating\").alias(\"num_livros\")\n",
        ").orderBy(\"years_since_last\")\n",
        "\n",
        "# Mostrar dados em tabela\n",
        "display(df_gap_trend)\n",
        "\n",
        "# Converter para pandas para plotar\n",
        "df_pd = df_gap_trend.toPandas()\n",
        "\n",
        "# ===========================================\n",
        "# 📈 VISUALIZAÇÃO\n",
        "# ===========================================\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_pd[\"years_since_last\"], df_pd[\"avg_rating\"], marker='o')\n",
        "plt.title(\"Nota Média por Intervalo de Lançamento entre Livros\")\n",
        "plt.xlabel(\"Anos desde o último livro\")\n",
        "plt.ylabel(\"Nota média\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#2. Intervalo entre lançamentos e nota média\n",
        "\n",
        "#Não foi observada uma relação linear entre o intervalo de tempo entre lançamentos e a nota média #dos livros. Autores que publicam com intervalos curtos (entre um e três anos) apresentam desempenho #semelhante àqueles com intervalos mais longos. Isso sugere que o tempo entre publicações, por si #só, não é um fator determinante para avaliações melhores. A consistência na produção pode ter papel #mais relevante que pausas prolongadas.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# 📊 GOLD - QTD DE LIVROS VS NOTA MÉDIA POR AUTOR (COM OUTLIERS E TENDÊNCIA)\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import count, avg, round, col\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1. Carregar tabela de livros por sequência\n",
        "df_sequence = spark.table(\"book_gold.books_ratings_by_sequence\")\n",
        "\n",
        "# 2. Agrupar por autor para obter total de livros e média de nota\n",
        "df_author_summary = df_sequence.groupBy(\"author\").agg(\n",
        "    count(\"title\").alias(\"qtd_livros\"),\n",
        "    round(avg(\"avg_rating\"), 2).alias(\"media_avaliacao\")\n",
        ").filter((col(\"qtd_livros\") >= 2) & (col(\"qtd_livros\") <= 100))\n",
        "\n",
        "# 3. Salvar como tabela auxiliar\n",
        "df_author_summary.write.mode(\"overwrite\").saveAsTable(\"book_gold.books_volume_vs_avg\")\n",
        "\n",
        "# 4. Visualização: gráfico de dispersão com linha de tendência e destaque de outliers\n",
        "# Converter para pandas\n",
        "df_pd = df_author_summary.toPandas()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Dispersão\n",
        "plt.scatter(df_pd[\"qtd_livros\"], df_pd[\"media_avaliacao\"], alpha=0.6, label=\"Autores\")\n",
        "\n",
        "# Linha de tendência (regressão linear)\n",
        "z = np.polyfit(df_pd[\"qtd_livros\"], df_pd[\"media_avaliacao\"], 1)\n",
        "p = np.poly1d(z)\n",
        "plt.plot(df_pd[\"qtd_livros\"], p(df_pd[\"qtd_livros\"]), \"r--\", label=\"Tendência\")\n",
        "\n",
        "# Outliers: autores com 80+ livros e média > 4.5\n",
        "outliers = df_pd[(df_pd[\"qtd_livros\"] >= 80) & (df_pd[\"media_avaliacao\"] > 4.5)]\n",
        "plt.scatter(outliers[\"qtd_livros\"], outliers[\"media_avaliacao\"], color='orange', edgecolors='black', label=\"Outliers\")\n",
        "\n",
        "# ===========================================\n",
        "# 📈 VISUALIZAÇÃO\n",
        "# ===========================================\n",
        "plt.title(\"Quantidade de Livros vs Média de Avaliação por Autor (até 100 livros)\")\n",
        "plt.xlabel(\"Quantidade de Livros\")\n",
        "plt.ylabel(\"Média das Notas\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#3. Quantidade de livros publicados e nota média\n",
        "\n",
        "#Há uma leve tendência de que autores com maior número de livros publicados apresentem uma média de #avaliação um pouco inferior. Ainda assim, alguns autores com alta produtividade conseguem manter #notas elevadas, aparecendo como exceções. Isso pode indicar que, embora a manutenção da qualidade #com volume alto seja desafiadora, ela é possível para certos perfis de autores.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# 📊 GOLD - IDADE DO LEITOR VS ANO DO LIVRO LIDO\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import col, floor, avg, count, when\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Carregar tabelas silver\n",
        "books = spark.table(\"book_silver.books\")\n",
        "ratings = spark.table(\"book_silver.ratings\")\n",
        "users = spark.table(\"book_silver.users\")\n",
        "\n",
        "# 2. Join completo\n",
        "ratings_books = ratings.join(books, on=\"isbn\", how=\"inner\")\n",
        "rating_data = ratings_books.join(users, on=\"user_id\", how=\"inner\")\n",
        "\n",
        "# 3. Filtrar dados consistentes\n",
        "rating_clean = rating_data.filter(\n",
        "    (col(\"age\").isNotNull()) & (col(\"age\") >= 10) & (col(\"age\") <= 100) &\n",
        "    (col(\"year\").isNotNull()) & (col(\"year\") >= 1450) & (col(\"year\") <= 2025)\n",
        ")\n",
        "\n",
        "# 4. Criar faixa etária\n",
        "rating_with_faixa = rating_clean.withColumn(\n",
        "    \"faixa_etaria\", (floor(col(\"age\") / 10) * 10).cast(\"int\")\n",
        ")\n",
        "\n",
        "# 5. Agrupar por faixa etária e calcular média do ano do livro\n",
        "df_idade_vs_ano = rating_with_faixa.groupBy(\"faixa_etaria\").agg(\n",
        "    round(avg(\"year\"), 1).alias(\"media_ano_lido\"),\n",
        "    count(\"isbn\").alias(\"total_livros_lidos\")\n",
        ").orderBy(\"faixa_etaria\")\n",
        "\n",
        "# 6. Salvar como tabela auxiliar\n",
        "df_idade_vs_ano.write.mode(\"overwrite\").saveAsTable(\"book_gold.reader_age_vs_book_year\")\n",
        "\n",
        "# ===========================================\n",
        "# 📈 VISUALIZAÇÃO\n",
        "# ===========================================\n",
        "# Converter para pandas\n",
        "df_pd = df_idade_vs_ano.toPandas()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_pd[\"faixa_etaria\"], df_pd[\"media_ano_lido\"], marker='o')\n",
        "plt.title(\"Média do Ano dos Livros Lidos por Faixa Etária do Leitor\")\n",
        "plt.xlabel(\"Faixa Etária\")\n",
        "plt.ylabel(\"Ano Médio dos Livros Lidos\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#4. Faixa etária do leitor e ano do livro lido\n",
        "\n",
        "#Os dados mostram que leitores mais jovens tendem a ler livros mais recentes, enquanto leitores com #mais idade consomem obras publicadas há mais tempo. Essa relação entre faixa etária e época da obra #lida pode refletir preferências geracionais ou maior familiaridade com obras de diferentes períodos.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# 📊 GOLD - AVALIAÇÃO POR IDADE DO LEITOR E ANO DO LIVRO (SUAVIZAÇÃO + ANOTAÇÕES)\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import col, floor, avg, count, round, expr\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from scipy.ndimage import uniform_filter\n",
        "\n",
        "# 1. Carregar tabelas base\n",
        "books = spark.table(\"book_silver.books\")\n",
        "ratings = spark.table(\"book_silver.ratings\")\n",
        "users = spark.table(\"book_silver.users\")\n",
        "\n",
        "# 2. Join completo\n",
        "ratings_books = ratings.join(books, on=\"isbn\", how=\"inner\")\n",
        "rating_data = ratings_books.join(users, on=\"user_id\", how=\"inner\")\n",
        "\n",
        "# 3. Filtrar dados válidos\n",
        "rating_clean = rating_data.filter(\n",
        "    (col(\"age\").isNotNull()) & (col(\"age\") >= 10) & (col(\"age\") <= 100) &\n",
        "    (col(\"year\").isNotNull()) & (col(\"year\") >= 1450) & (col(\"year\") <= 2025)\n",
        ")\n",
        "\n",
        "# 4. Criar faixas\n",
        "rating_with_bins = rating_clean.withColumn(\"faixa_etaria\", (floor(col(\"age\") / 10) * 10).cast(\"int\")) \\\n",
        "    .withColumn(\"ano_livro\", (floor(col(\"year\") / 10) * 10).cast(\"int\"))\n",
        "\n",
        "# 5. Agrupar e calcular médias\n",
        "df_avaliacoes = rating_with_bins.groupBy(\"faixa_etaria\", \"ano_livro\").agg(\n",
        "    round(avg(\"rating\"), 2).alias(\"avg_rating\"),\n",
        "    count(\"rating\").alias(\"total_avaliacoes\")\n",
        ").orderBy(\"faixa_etaria\", \"ano_livro\")\n",
        "\n",
        "# 6. Salvar tabela gold auxiliar\n",
        "df_avaliacoes.write.mode(\"overwrite\").saveAsTable(\"book_gold.age_book_year_rating\")\n",
        "\n",
        "# 7. Visualização: mapa de calor com suavização e anotações\n",
        "# Converter para pandas\n",
        "pdf = df_avaliacoes.toPandas()\n",
        "\n",
        "# Pivot para heatmap\n",
        "pivot = pdf.pivot(index=\"faixa_etaria\", columns=\"ano_livro\", values=\"avg_rating\")\n",
        "\n",
        "# Aplicar suavização com filtro de média (janela 3x3)\n",
        "smoothed = uniform_filter(pivot.fillna(0), size=3)\n",
        "\n",
        "# Criar DataFrame suavizado com mesmos índices para anotação\n",
        "smoothed_df = pd.DataFrame(smoothed, index=pivot.index, columns=pivot.columns)\n",
        "\n",
        "# ===========================================\n",
        "# 📈 VISUALIZAÇÃO\n",
        "# ===========================================\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.heatmap(smoothed_df, annot=smoothed_df.round(2), fmt=\".2f\", cmap=\"YlGnBu\", linewidths=0.5)\n",
        "plt.title(\"Média de Avaliação por Faixa Etária do Leitor e Ano do Livro (Suavizado)\")\n",
        "plt.xlabel(\"Ano do Livro (décadas)\")\n",
        "plt.ylabel(\"Faixa Etária do Leitor\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#6. Diversidade de autores por faixa etária\n",
        "\n",
        "#Leitores com idade entre 30 e 45 anos tendem a ter contato com uma maior variedade de autores, #especialmente nas faixas entre 12 e 24 autores distintos. Por outro lado, leitores mais jovens (até #20 anos) e mais velhos (acima de 65) demonstram menor diversidade. Isso sugere que, na fase adulta, #há maior disposição para explorar diferentes estilos e autores.\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# 📊 GOLD - DISTRIBUIÇÃO DE DIVERSIDADE DE AUTORES POR FAIXA ETÁRIA DO LEITOR\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import col, floor, countDistinct\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Carregar tabelas silver\n",
        "books = spark.table(\"book_silver.books\")\n",
        "ratings = spark.table(\"book_silver.ratings\")\n",
        "users = spark.table(\"book_silver.users\")\n",
        "\n",
        "# 2. Join completo\n",
        "ratings_books = ratings.join(books, on=\"isbn\", how=\"inner\")\n",
        "rating_data = ratings_books.join(users, on=\"user_id\", how=\"inner\")\n",
        "\n",
        "# 3. Filtrar dados válidos\n",
        "rating_clean = rating_data.filter(\n",
        "    (col(\"age\").isNotNull()) & (col(\"age\") >= 10) & (col(\"age\") <= 100) &\n",
        "    (col(\"author\").isNotNull()) & (col(\"author\") != \"\")\n",
        ")\n",
        "\n",
        "# 4. Criar faixa etária de 5 em 5 anos\n",
        "rating_with_bins = rating_clean.withColumn(\"faixa_etaria\", (floor(col(\"age\") / 5) * 5).cast(\"int\"))\n",
        "\n",
        "# 5. Calcular autores distintos por leitor\n",
        "user_author_counts = rating_with_bins.groupBy(\"user_id\", \"faixa_etaria\").agg(\n",
        "    countDistinct(\"author\").alias(\"autores_distintos\")\n",
        ")\n",
        "\n",
        "# 6. Aplicar limite e criar faixas de diversidade de autores (3 em 3)\n",
        "auth_bin_df = user_author_counts.filter(col(\"autores_distintos\") <= 30) \\\n",
        "    .withColumn(\"faixa_autores\", (floor(col(\"autores_distintos\") / 3) * 3).cast(\"int\"))\n",
        "\n",
        "# 7. Contar usuários por faixa de idade e faixa de diversidade\n",
        "distribuicao_df = auth_bin_df.groupBy(\"faixa_etaria\", \"faixa_autores\").count().orderBy(\"faixa_etaria\", \"faixa_autores\")\n",
        "\n",
        "# 8. Converter para pandas e pivotar\n",
        "pdf = distribuicao_df.toPandas()\n",
        "pivot = pdf.pivot(index=\"faixa_autores\", columns=\"faixa_etaria\", values=\"count\").fillna(0)\n",
        "\n",
        "# ===========================================\n",
        "# 📈 VISUALIZAÇÃO\n",
        "# ===========================================\n",
        "# 9. Visualizar como heatmap\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.heatmap(pivot, annot=True, fmt=\".0f\", cmap=\"YlOrBr\", linewidths=0.5)\n",
        "plt.title(\"Distribuição de Diversidade de Autores por Faixa Etária do Leitor (até 30 autores, agrupado de 3 em 3)\")\n",
        "plt.xlabel(\"Faixa Etária (anos)\")\n",
        "plt.ylabel(\"Número de Autores Distintos (agrupado de 3 em 3)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#6. Diversidade de autores por faixa etária\n",
        "\n",
        "#Leitores com idade entre 30 e 45 anos tendem a ter contato com uma maior variedade de autores, #especialmente nas faixas entre 12 e 24 autores distintos. Por outro lado, leitores mais jovens (até #20 anos) e mais velhos (acima de 65) demonstram menor diversidade. Isso sugere que, na fase adulta, #há maior disposição para explorar diferentes estilos e autores.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# 📊 GOLD - CLUSTERIZAÇÃO DE AUTORES\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import col, avg, stddev, count, round\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Carregar tabela de sequência com notas por livro\n",
        "df = spark.table(\"book_gold.books_ratings_by_sequence\")\n",
        "\n",
        "# 2. Agregar por autor para gerar métricas\n",
        "autores_df = df.groupBy(\"author\").agg(\n",
        "    count(\"title\").alias(\"qtd_livros\"),\n",
        "    round(avg(\"avg_rating\"), 2).alias(\"media_nota\"),\n",
        "    round(stddev(\"avg_rating\"), 2).alias(\"desvio_nota\"),\n",
        "    round(avg(\"year\"), 0).alias(\"ano_medio\")\n",
        ").filter(col(\"qtd_livros\") >= 3)\n",
        "\n",
        "# 3. Vetorizar para ML\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"qtd_livros\", \"media_nota\", \"desvio_nota\", \"ano_medio\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "vectorized_df = assembler.transform(autores_df)\n",
        "\n",
        "# 4. Padronizar os dados\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled\", withMean=True, withStd=True)\n",
        "scaler_model = scaler.fit(vectorized_df)\n",
        "scaled_df = scaler_model.transform(vectorized_df)\n",
        "\n",
        "# 5. Aplicar KMeans (definindo 4 clusters)\n",
        "kmeans = KMeans(featuresCol=\"scaled\", predictionCol=\"cluster\", k=4, seed=42)\n",
        "model = kmeans.fit(scaled_df)\n",
        "clustered = model.transform(scaled_df)\n",
        "\n",
        "# 6. Converter para pandas para visualização\n",
        "pdf = clustered.select(\"author\", \"qtd_livros\", \"media_nota\", \"desvio_nota\", \"ano_medio\", \"cluster\").toPandas()\n",
        "\n",
        "# ===========================================\n",
        "# 📈 VISUALIZAÇÃO\n",
        "# ===========================================\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=pdf, x=\"qtd_livros\", y=\"media_nota\", hue=\"cluster\", palette=\"Set2\")\n",
        "plt.title(\"Clusterização de Autores por Volume e Nota Média\")\n",
        "plt.xlabel(\"Quantidade de Livros\")\n",
        "plt.ylabel(\"Média das Notas\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 8. Salvar tabela com clusters\n",
        "spark.createDataFrame(pdf).write.mode(\"overwrite\").saveAsTable(\"book_gold.authors_clustered\")\n",
        "\n",
        "#7. Clusterização de autores\n",
        "\n",
        "#A segmentação dos autores com base em volume de livros publicados, nota média, desvio das #avaliações e ano médio das obras permitiu identificar perfis distintos. Foram encontrados #agrupamentos com autores prolíficos e bem avaliados, autores com alta variabilidade nas avaliações #e autores mais recentes com desempenho positivo. Esta análise permite mapear padrões de atuação no #cenário literário.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# 🌍 GOLD - CLUSTERIZAÇÃO DE PAÍSES POR FAIXAS ETÁRIAS (PROPORÇÃO POR FAIXA ORDENADO POR TOTAL)\n",
        "# ===========================================\n",
        "from pyspark.sql.functions import col, lower, split, trim, regexp_replace, count, floor, sum as sum_\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Carregar tabela de usuários\n",
        "users = spark.table(\"book_silver.users\")\n",
        "\n",
        "# 2. Extrair país após a segunda vírgula\n",
        "users_country = users.withColumn(\"country_raw\", split(col(\"location\"), \",\").getItem(2)) \\\n",
        "    .withColumn(\"country\", regexp_replace(trim(lower(col(\"country_raw\"))), \"[^a-z ]\", \"\")) \\\n",
        "    .filter(col(\"country\").isNotNull() & (col(\"country\") != \"\"))\n",
        "\n",
        "# 3. Filtrar idades válidas\n",
        "users_valid_age = users_country.filter((col(\"age\") >= 10) & (col(\"age\") <= 100))\n",
        "\n",
        "# 4. Criar faixa etária de 5 em 5 anos\n",
        "users_with_bins = users_valid_age.withColumn(\"faixa_etaria\", (floor(col(\"age\") / 5) * 5).cast(\"int\"))\n",
        "\n",
        "# 5. Contar número de leitores por país e faixa etária\n",
        "df_country_faixa = users_with_bins.groupBy(\"country\", \"faixa_etaria\").agg(count(\"user_id\").alias(\"total\"))\n",
        "\n",
        "# 6. Selecionar os 30 países com mais leitores no total\n",
        "total_by_country = df_country_faixa.groupBy(\"country\").agg(sum_(\"total\").alias(\"total_pais\"))\n",
        "top30_countries = total_by_country.orderBy(col(\"total_pais\").desc()).limit(30)\n",
        "df_top30 = df_country_faixa.join(top30_countries.select(\"country\"), on=\"country\", how=\"inner\")\n",
        "\n",
        "# 7. Calcular proporção por faixa etária em cada país\n",
        "df_top30_total = df_top30.join(total_by_country.withColumnRenamed(\"total_pais\", \"total_pais_all\"), on=\"country\")\n",
        "df_top30_prop = df_top30_total.withColumn(\"proporcao\", (col(\"total\") / col(\"total_pais_all\")).cast(\"double\"))\n",
        "\n",
        "# 8. Pivotar proporções por faixa etária\n",
        "df_pivot = df_top30_prop.groupBy(\"country\").pivot(\"faixa_etaria\").agg({\"proporcao\": \"avg\"}).na.fill(0)\n",
        "\n",
        "# 9. Clusterização com KMeans por distribuição etária proporcional\n",
        "features = [col for col in df_pivot.columns if col != \"country\"]\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "data_vector = assembler.transform(df_pivot)\n",
        "\n",
        "kmeans = KMeans(k=4, seed=42, featuresCol=\"features\", predictionCol=\"cluster\")\n",
        "model = kmeans.fit(data_vector)\n",
        "clustered = model.transform(data_vector)\n",
        "\n",
        "# ===========================================\n",
        "# 📈 VISUALIZAÇÃO\n",
        "# ===========================================\n",
        "# 10. Expandir para gráfico de bolhas com proporção e ordenação por total\n",
        "df_expanded = df_top30_prop.join(clustered.select(\"country\", \"cluster\"), on=\"country\", how=\"inner\")\n",
        "df_expanded = df_expanded.join(top30_countries, on=\"country\")\n",
        "pdf_bubbles = df_expanded.select(\"country\", \"faixa_etaria\", \"proporcao\", \"cluster\", \"total_pais\").toPandas()\n",
        "pdf_bubbles[\"country\"] = pd.Categorical(pdf_bubbles[\"country\"], \n",
        "    categories=pdf_bubbles.groupby(\"country\")[\"total_pais\"].max().sort_values(ascending=False).index,\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "# 11. Visualização com gráfico de bolhas\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.scatterplot(\n",
        "    data=pdf_bubbles,\n",
        "    x=\"faixa_etaria\",\n",
        "    y=\"country\",\n",
        "    size=\"proporcao\",\n",
        "    hue=\"cluster\",\n",
        "    sizes=(40, 800),\n",
        "    alpha=0.7,\n",
        "    palette=\"Set2\"\n",
        ")\n",
        "plt.title(\"Distribuição Proporcional de Leitores por Faixa Etária e País (Ordenado por Volume)\")\n",
        "plt.xlabel(\"Faixa Etária\")\n",
        "plt.ylabel(\"País (ordenado por total de leitores)\")\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#8. Clusterização de países por faixa etária\n",
        "\n",
        "#A análise por país, considerando a proporção de leitores por faixa etária, mostrou perfis distintos #entre as nações. Países como Estados Unidos, Índia e Alemanha apresentaram maior equilíbrio etário, #enquanto outros se destacaram por concentrações em faixas mais jovens. Essa informação pode indicar #variações no hábito de leitura e ajudar a identificar oportunidades de atuação segmentada por #região.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
