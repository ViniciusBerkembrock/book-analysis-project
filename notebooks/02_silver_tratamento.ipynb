{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===========================================\n",
        "# ğŸ’¾ SILVER - LIMPEZA, PADRONIZAÃ‡ÃƒO E SALVAMENTO (VERSÃƒO FINAL REFORÃ‡ADA)\n",
        "# ===========================================\n",
        "\n",
        "from pyspark.sql.functions import col, when, regexp_replace, lower, trim, length, min as min_, max as max_\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# ========================\n",
        "# ğŸ§¹ LIMPEZA DE DADOS\n",
        "# ========================\n",
        "\n",
        "# Books (sem ISBN nulo ou vazio)\n",
        "df_books_bronze = spark.table(\"book_bronze.books\")\n",
        "df_books_clean = df_books_bronze.filter(col(\"ISBN\").isNotNull() & (col(\"ISBN\") != \"\"))\n",
        "\n",
        "# Ratings (sem user_id ou isbn nulos)\n",
        "df_ratings_bronze = spark.table(\"book_bronze.ratings\")\n",
        "df_ratings_clean = df_ratings_bronze.filter(col(\"User-ID\").isNotNull() & col(\"ISBN\").isNotNull())\n",
        "\n",
        "# Users (filtrando idade fora da faixa)\n",
        "df_users_bronze = spark.table(\"book_bronze.users\")\n",
        "df_users_clean = df_users_bronze.filter(\n",
        "    col(\"User-ID\").isNotNull() & \n",
        "    (col(\"Age\").cast(\"int\") >= 5) & (col(\"Age\").cast(\"int\") <= 100)\n",
        ")\n",
        "\n",
        "# ========================\n",
        "# âœï¸ PADRONIZAÃ‡ÃƒO\n",
        "# ========================\n",
        "\n",
        "# Books - padronizaÃ§Ã£o e limpeza extra de author e publisher\n",
        "df_books_silver_raw = df_books_clean.select(\n",
        "    col(\"ISBN\").alias(\"isbn\"),\n",
        "    col(\"Book-Title\").alias(\"title\"),\n",
        "    regexp_replace(\n",
        "        regexp_replace(trim(lower(col(\"Book-Author\"))), r'&amp;', '&'),\n",
        "        r'[\\\"â€œâ€]+', ''\n",
        "    ).alias(\"author\"),\n",
        "    col(\"Year-Of-Publication\").cast(\"int\").alias(\"year\"),\n",
        "    regexp_replace(trim(lower(col(\"Publisher\"))), r'&amp;', '&').alias(\"publisher\"),\n",
        "    col(\"Image-URL-S\").alias(\"img_url_s\"),\n",
        "    col(\"Image-URL-M\").alias(\"img_url_m\"),\n",
        "    col(\"Image-URL-L\").alias(\"img_url_l\")\n",
        ").filter(\n",
        "    (col(\"author\").isNotNull()) &\n",
        "    (length(col(\"author\")) > 3) &\n",
        "    (~col(\"author\").rlike(\"^[0-9]+$\")) &\n",
        "    (~col(\"author\").rlike(\"[0-9]{4,}\")) &\n",
        "    (~col(\"author\").rlike(\"committee|conference|school|publishers|ltd|inaugural|collection\")) &\n",
        "    (~col(\"author\").rlike(\"^[;:\\\\-]\")) &\n",
        "    (~col(\"author\").rlike(\"\\\\:\")) &\n",
        "    (col(\"year\").isNotNull()) &\n",
        "    (col(\"year\") >= 1450) &\n",
        "    (col(\"year\") <= 2025)\n",
        ")\n",
        "\n",
        "# Remover autores cujo intervalo de anos entre livros seja 50 ou mais\n",
        "year_window = Window.partitionBy(\"author\")\n",
        "df_books_silver_filtered = df_books_silver_raw.withColumn(\"min_year\", min_(\"year\").over(year_window)) \\\n",
        "                                                   .withColumn(\"max_year\", max_(\"year\").over(year_window)) \\\n",
        "                                                   .filter((col(\"max_year\") - col(\"min_year\")) < 50) \\\n",
        "                                                   .drop(\"min_year\", \"max_year\")\n",
        "\n",
        "# Ratings\n",
        "ratings_pad = df_ratings_clean.select(\n",
        "    col(\"User-ID\").alias(\"user_id\"),\n",
        "    col(\"ISBN\").alias(\"isbn\"),\n",
        "    col(\"Book-Rating\").alias(\"rating\")\n",
        ")\n",
        "\n",
        "# Users\n",
        "users_pad = df_users_clean.select(\n",
        "    col(\"User-ID\").alias(\"user_id\"),\n",
        "    trim(lower(col(\"Location\"))).alias(\"location\"),\n",
        "    col(\"Age\").cast(\"int\").alias(\"age\")\n",
        ")\n",
        "\n",
        "# ========================\n",
        "# ğŸ”— ESTRUTURAÃ‡ÃƒO DE TABELAS\n",
        "# ========================\n",
        "\n",
        "# Remover duplicados\n",
        "books_unique = df_books_silver_filtered.dropDuplicates([\"isbn\"])\n",
        "ratings_unique = ratings_pad.dropDuplicates()\n",
        "users_unique = users_pad.dropDuplicates([\"user_id\"])\n",
        "\n",
        "# Tabela auxiliar: autores Ãºnicos\n",
        "authors_raw = books_unique.select(\"author\").distinct()\n",
        "\n",
        "# ========================\n",
        "# ğŸ§¹ LIMPEZA DE TABELAS EXISTENTES (se houver)\n",
        "# ========================\n",
        "\n",
        "spark.sql(\"DROP TABLE IF EXISTS book_silver.books\")\n",
        "spark.sql(\"DROP TABLE IF EXISTS book_silver.ratings\")\n",
        "spark.sql(\"DROP TABLE IF EXISTS book_silver.users\")\n",
        "spark.sql(\"DROP TABLE IF EXISTS book_silver.authors_raw\")\n",
        "\n",
        "# ========================\n",
        "# ğŸ’¾ SALVAMENTO FINAL\n",
        "# ========================\n",
        "\n",
        "books_unique.write.mode(\"overwrite\").saveAsTable(\"book_silver.books\")\n",
        "ratings_unique.write.mode(\"overwrite\").saveAsTable(\"book_silver.ratings\")\n",
        "users_unique.write.mode(\"overwrite\").saveAsTable(\"book_silver.users\")\n",
        "authors_raw.write.mode(\"overwrite\").saveAsTable(\"book_silver.authors_raw\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
